{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install the RLDS and other required modules**"
      ],
      "metadata": {
        "id": "WqSMLFYGB7KE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "V8k_ipftBuVG"
      },
      "outputs": [],
      "source": [
        "!pip install rlds[tensorflow]\n",
        "!pip install tfds-nightly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apache-beam"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kIwZbHWnIJd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Dict, Union, NamedTuple\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import rlds"
      ],
      "metadata": {
        "id": "dg5oedGFCATS"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Choose an RLDS dataset - Choosing D4RL MuJoCo Hopper as an example**"
      ],
      "metadata": {
        "id": "0GcbuyJlPe-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'd4rl_mujoco_hopper'  # @param { isTemplate: true}\n",
        "num_episodes_to_load = 10   # @param { isTemplate: true}"
      ],
      "metadata": {
        "id": "uqMdogYMCMaL"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, info = tfds.load(dataset_name, with_info=True)"
      ],
      "metadata": {
        "id": "eNRsVd0UF4oJ"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Print information about the dataset and its format**"
      ],
      "metadata": {
        "id": "GjCiSv0PPlNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALP1XBbXI6ab",
        "outputId": "a42fe1ee-3445-4915-ecc4-353378bead02"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='d4rl_mujoco_hopper',\n",
            "    full_name='d4rl_mujoco_hopper/v0-expert/1.2.0',\n",
            "    description=\"\"\"\n",
            "    D4RL is an open-source benchmark for offline reinforcement learning. It provides\n",
            "    standardized environments and datasets for training and benchmarking algorithms.\n",
            "    \n",
            "    The datasets follow the [RLDS format](https://github.com/google-research/rlds)\n",
            "    to represent steps and episodes.\n",
            "    \"\"\",\n",
            "    config_description=\"\"\"\n",
            "    See more details about the task and its versions in https://github.com/rail-berkeley/d4rl/wiki/Tasks#gym\n",
            "    \"\"\",\n",
            "    homepage='https://sites.google.com/view/d4rl-anonymous',\n",
            "    data_dir='/root/tensorflow_datasets/d4rl_mujoco_hopper/v0-expert/1.2.0',\n",
            "    file_format=tfrecord,\n",
            "    download_size=51.56 MiB,\n",
            "    dataset_size=64.10 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'steps': Dataset({\n",
            "            'action': Tensor(shape=(3,), dtype=float32),\n",
            "            'discount': float32,\n",
            "            'is_first': bool,\n",
            "            'is_last': bool,\n",
            "            'is_terminal': bool,\n",
            "            'observation': Tensor(shape=(11,), dtype=float32),\n",
            "            'reward': float32,\n",
            "        }),\n",
            "    }),\n",
            "    supervised_keys=None,\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'train': <SplitInfo num_examples=1029, num_shards=1>,\n",
            "    },\n",
            "    citation=\"\"\"@misc{fu2020d4rl,\n",
            "        title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},\n",
            "        author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},\n",
            "        year={2020},\n",
            "        eprint={2004.07219},\n",
            "        archivePrefix={arXiv},\n",
            "        primaryClass={cs.LG}\n",
            "    }\"\"\",\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**View Episode and Step structure - specifically the actions**"
      ],
      "metadata": {
        "id": "anTSPAmYPo2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single episode from the dataset\n",
        "\n",
        "## Format of the dataset is RLDS:\n",
        "## Episode: [step: [action, reward, observation,...], step, step...], Episode, Episode...\n",
        "## To understand how actions, observations, and reward are represented, refer to MuJoCo Hopper docs: https://gymnasium.farama.org/environments/mujoco/hopper/\n",
        "\n",
        "\n",
        "print(dataset['train'])\n",
        "\n",
        "episode = next(iter(dataset['train']))\n",
        "\n",
        "# Print episode structure\n",
        "print(\"\\nEpisode Structure:\")\n",
        "print(episode.items())\n",
        "\n",
        "\n",
        "for item in episode.items():\n",
        "\n",
        "    #Using numpy_iterator to query the elements in the _VariantDataset element_spec data format\n",
        "    ele  = item[1].as_numpy_iterator()\n",
        "    ele_iterated = np.array([val for val in ele])\n",
        "    #print(ele_iterated)\n",
        "    print(\"\\n\")\n",
        "    print(len(ele_iterated))\n",
        "    print('\\naction:')\n",
        "    print(ele_iterated[0]['action'])\n",
        "    print(len(ele_iterated[0]['action']))\n",
        "    print('\\nobservation:')\n",
        "    print(ele_iterated[0]['observation'])\n",
        "    print(len(ele_iterated[0]['observation']))\n",
        "    print('\\nreward:')\n",
        "    print(ele_iterated[0]['reward'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lif-0CvoLjgV",
        "outputId": "e3c01f5d-6b3f-4c63-91c3-3ee11c615265"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec={'steps': DatasetSpec({'action': TensorSpec(shape=(3,), dtype=tf.float32, name=None), 'discount': TensorSpec(shape=(), dtype=tf.float32, name=None), 'is_first': TensorSpec(shape=(), dtype=tf.bool, name=None), 'is_last': TensorSpec(shape=(), dtype=tf.bool, name=None), 'is_terminal': TensorSpec(shape=(), dtype=tf.bool, name=None), 'observation': TensorSpec(shape=(11,), dtype=tf.float32, name=None), 'reward': TensorSpec(shape=(), dtype=tf.float32, name=None)}, TensorShape([]))}>\n",
            "\n",
            "Episode Structure:\n",
            "dict_items([('steps', <_VariantDataset element_spec={'action': TensorSpec(shape=(3,), dtype=tf.float32, name=None), 'discount': TensorSpec(shape=(), dtype=tf.float32, name=None), 'is_first': TensorSpec(shape=(), dtype=tf.bool, name=None), 'is_last': TensorSpec(shape=(), dtype=tf.bool, name=None), 'is_terminal': TensorSpec(shape=(), dtype=tf.bool, name=None), 'observation': TensorSpec(shape=(11,), dtype=tf.float32, name=None), 'reward': TensorSpec(shape=(), dtype=tf.float32, name=None)}>)])\n",
            "\n",
            "\n",
            "999\n",
            "\n",
            "action:\n",
            "[ 0.6785188 -0.7910777  0.8783449]\n",
            "3\n",
            "\n",
            "observation:\n",
            "[ 1.2466857e+00 -4.5541851e-03 -2.0240126e-03 -2.6647206e-03\n",
            "  3.7273685e-03  2.6800125e-03  3.8231765e-03 -8.3481689e-04\n",
            " -4.0751291e-03  2.0884005e-03  2.1104529e-03]\n",
            "11\n",
            "\n",
            "reward:\n",
            "0.9843637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Choose an HF JAT dataset - Choosing MuJoCo Hopper as an example**"
      ],
      "metadata": {
        "id": "SJAE2dPITozG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CZxW-coRTtCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "mCHCYF3SLrNK"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_hf = load_dataset(\"jat-project/jat-dataset\", \"mujoco-hopper\")"
      ],
      "metadata": {
        "id": "qP1_OIJOTrwt"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check structure of HF dataset**"
      ],
      "metadata": {
        "id": "zS-azSnpZtf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_hf['train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar0KtCEJWXNe",
        "outputId": "b6c13b39-37cf-40fa-8144-3de649d7130b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['continuous_observations', 'continuous_actions', 'rewards'],\n",
            "    num_rows: 9000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_episode = dataset_hf[\"train\"][0]\n",
        "print(first_episode)"
      ],
      "metadata": {
        "id": "-batNWe0Vg2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting the HF JAT dataset to the TFDS format**"
      ],
      "metadata": {
        "id": "V8FSISVIbhM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_datasets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Pqy6AjPfcr7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow_datasets import dataset_builders"
      ],
      "metadata": {
        "id": "HfT43kF2bliL"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_ds = dataset_builders.HuggingfaceDatasetBuilder(hf_repo_id= \"jat-project/jat-dataset\", hf_config= \"mujoco-hopper\")"
      ],
      "metadata": {
        "id": "SGAsHIiqpgEu"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_ds.download_and_prepare()"
      ],
      "metadata": {
        "id": "YVG6BT80NETd"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_ds_converted = tf_ds.as_dataset()"
      ],
      "metadata": {
        "id": "dnpxiJBdNOtV"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**View Episode and Step structure - specifically the actions**"
      ],
      "metadata": {
        "id": "GXN3-KLdaLjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Format of the dataset:\n",
        "## Episode: {continuous_actions: action x num_steps, continuous_observations: observation x num_steps, rewards: reward x num_steps}, Episode, Episode,...\n",
        "## To understand how actions, observations, and reward are represented, refer to MuJoCo Hopper docs: https://gymnasium.farama.org/environments/mujoco/hopper/\n",
        "\n",
        "episode_tfds = next(iter(tf_ds_converted['train']))\n",
        "print(len(episode_tfds))\n",
        "\n",
        "# Print episode structure\n",
        "print(\"\\nEpisode Structure:\\n\")\n",
        "\n",
        "for item in episode_tfds.items():\n",
        "\n",
        "    print(item[0])\n",
        "    print(item[1][0])\n",
        "    print(item[1][0].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykneEx8VQeDa",
        "outputId": "6a08008f-5896-4930-9243-9d96dae461a4"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "\n",
            "Episode Structure:\n",
            "\n",
            "continuous_actions\n",
            "tf.Tensor([ 0.7731227  -0.12329477  1.4207025 ], shape=(3,), dtype=float32)\n",
            "(3,)\n",
            "continuous_observations\n",
            "tf.Tensor(\n",
            "[ 1.24644172e+00 -2.62443000e-03 -2.58111744e-03 -3.67255905e-03\n",
            " -3.42490990e-03  3.84315057e-03  3.58732208e-03  5.19199471e-04\n",
            "  1.38649053e-03 -4.60560387e-03 -1.09901805e-04], shape=(11,), dtype=float32)\n",
            "(11,)\n",
            "rewards\n",
            "tf.Tensor(1.0301455, shape=(), dtype=float32)\n",
            "()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YpOUmlC06l8-"
      },
      "execution_count": 101,
      "outputs": []
    }
  ]
}