{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f5cdb-c46d-4b83-92d2-a9ecad11a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab95643-d542-46bd-ba99-6bc894c825f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_from_json(data, key):\n",
    "    \"\"\"Recursively extract value of a specified key from nested JSON-like structures. \"\"\"\n",
    "    if isinstance(data, list):\n",
    "        values = []\n",
    "        for item in data:\n",
    "            values.extend(extract_key_from_json(item, key))\n",
    "        return values\n",
    "    elif isinstance(data, dict):\n",
    "        values = []\n",
    "        for k, v in data.items():\n",
    "            if k == key:\n",
    "                values.append(v)\n",
    "            else:\n",
    "                values.extend(extract_key_from_json(v, key))\n",
    "        return values\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "def extract_per_subtask_metric(data, metric_key) -> dict[str, float]:\n",
    "    \"\"\"Extract per subtask metric from the Json data. Returned as a dictionary mapping task names to their respective metric values.\"\"\"\n",
    "    # look through the nested structure to find the subtask with the metric_key\n",
    "    result = {}\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            result.update(extract_per_subtask_metric(item, metric_key))\n",
    "    elif isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            if metric_key in v:\n",
    "                result[k] = v[metric_key]\n",
    "            else:\n",
    "                result.update(extract_per_subtask_metric(v, metric_key))\n",
    "    return result\n",
    "\n",
    "def barplot(dataframe, title, ylabel, xlabel, save_path, y='Exact Match Rate'):\n",
    "    # set seaborn style\n",
    "    sns.set_theme(style='darkgrid')\n",
    "    # each dataframe contains a column indicating the model (gpt5 or pi0), a column indicating the task, and a column indicating the emr\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(x='Task', y=y, hue='Model', data=dataframe)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(title='Model')\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "# mapping from different ways of naming the same subtask in openx results\n",
    "openx_subtasks_mapping = {\n",
    "    'openx_bimanual': 'bimanual',\n",
    "    'openx_quadrupedal': 'quadrupedal',\n",
    "    'openx_mobile_manipulation': 'mobile_manipulation',\n",
    "    'openx_single_arm': 'single_arm',\n",
    "    'openx_wheeled_robot': 'wheeled_robot',\n",
    "    'berkeley_gnm_sac_son': 'wheeled_robot',\n",
    "    'utokyo_saytap_converted_externally_to_rlds':'quadrupedal',\n",
    "    'bridge': 'single_arm',\n",
    "    'utokyo_arm_bimanual_converted_externally_to_rlds': 'bimanual',\n",
    "    'fractal20220817_data': 'mobile_manipulation',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb44e3ff-23a3-4839-ac04-caf9aadf0be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the openx json file\n",
    "with open('./pi0/pi0_base_openx_results_final.json') as f:\n",
    "    pi0_base_openx = json.load(f)\n",
    "# load the overcooked json file\n",
    "with open('./pi0/pi0_base_overcooked_results.json') as f:\n",
    "    pi0_base_overcooked = json.load(f)\n",
    "# load the hf bfcl inference results json file\n",
    "with open('./pi0/pi0_hf_bfcl_inference_results.json') as f:\n",
    "    pi0_hf_bfcl_inference = json.load(f)\n",
    "# load the hf piqa results json file\n",
    "with open('./pi0/pi0_hf_piqa_inference_results.json') as f:\n",
    "    pi0_hf_piqa = json.load(f)\n",
    "# load the hf robovqa results json file\n",
    "with open('./pi0/pi0_hf_robovqa_inference_results.json') as f:\n",
    "    pi0_hf_robovqa = json.load(f)\n",
    "# load the hf sqa3d results json file\n",
    "with open('./pi0/pi0_hf_sqa3d_inference_results.json') as f:\n",
    "    pi0_hf_sqa3d = json.load(f)\n",
    "# load all the json files in the odinw folder\n",
    "pi0_odinw_results = []\n",
    "for file in os.listdir('./pi0/odinw'):\n",
    "    if file.endswith('.json'):\n",
    "        with open(os.path.join('./pi0/odinw', file)) as f:\n",
    "            pi0_odinw_results.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498f803-0e13-4a14-ba4d-15f8dac35528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the all openx json files\n",
    "gpt5_openx = []\n",
    "for file in os.listdir('./genesis/gpt_5/low_reasoning/openx'):\n",
    "    if file.endswith('.json'):\n",
    "        with open(os.path.join('./genesis/gpt_5/low_reasoning/openx', file)) as f:\n",
    "            gpt5_openx.append(json.load(f))\n",
    "# load all odinw json files\n",
    "gpt5_odinw = []\n",
    "for file in os.listdir('./genesis/gpt_5/low_reasoning/odinw'):\n",
    "    if file.endswith('.json'):\n",
    "        with open(os.path.join('./genesis/gpt_5/low_reasoning/odinw', file)) as f:\n",
    "            gpt5_odinw.append(json.load(f))\n",
    "# load all overcooked json files\n",
    "gpt5_overcooked = []\n",
    "for file in os.listdir('./genesis/gpt_5/low_reasoning/overcooked_ai'):\n",
    "    if file.endswith('.json'):\n",
    "        with open(os.path.join('./genesis/gpt_5/low_reasoning/overcooked_ai', file)) as f:\n",
    "            gpt5_overcooked.append(json.load(f))\n",
    "# load all piqa json files\n",
    "gpt5_piqa = []\n",
    "for file in os.listdir('./genesis/gpt_5/low_reasoning/piqa'):\n",
    "    if file.endswith('.json'):\n",
    "        with open(os.path.join('./genesis/gpt_5/low_reasoning/piqa', file)) as f:\n",
    "            gpt5_piqa.append(json.load(f))\n",
    "# load all robot_vqa json files\n",
    "gpt5_robovqa = []\n",
    "for file in os.listdir('./genesis/gpt_5/low_reasoning/robot_vqa'):\n",
    "    if file.endswith('.json'):\n",
    "        with open(os.path.join('./genesis/gpt_5/low_reasoning/robot_vqa', file)) as f:\n",
    "            gpt5_robovqa.append(json.load(f))\n",
    "# load all sqa3d json files\n",
    "gpt5_sqa3d = []\n",
    "for file in os.listdir('./genesis/gpt_5/low_reasoning/sqa3d'):\n",
    "    if file.endswith('.json'):\n",
    "        with open(os.path.join('./genesis/gpt_5/low_reasoning/sqa3d', file)) as f:\n",
    "            gpt5_sqa3d.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the openx json file\n",
    "with open('./magma/magma_openx_results_final.json') as f:\n",
    "    magma_openx = json.load(f)\n",
    "# # load the overcooked json file\n",
    "# with open('./magma/magma_overcooked_results.json') as f:\n",
    "#     magma_overcooked = json.load(f)\n",
    "# # load the hf bfcl inference results json file\n",
    "# with open('./magma/magma_bfcl_inference_results.json') as f:\n",
    "#     magma_bfcl_inference = json.load(f)\n",
    "# load the hf piqa results json file\n",
    "with open('./magma/piqa_results.json') as f:\n",
    "    magma_piqa = json.load(f)\n",
    "# load the hf robovqa results json file\n",
    "with open('./magma/robovqa_results.json') as f:\n",
    "    magma_robovqa = json.load(f)\n",
    "# load the hf sqa3d results json file\n",
    "with open('./magma/sqa3d_results.json') as f:\n",
    "    magma_sqa3d = json.load(f)\n",
    "# load all the json files in the odinw folder\n",
    "magma_odinw_results = []\n",
    "for file in os.listdir('./magma/odinw/corrected_results'):\n",
    "    if file.endswith('.json'):\n",
    "        with open(os.path.join('./magma/odinw/corrected_results', file)) as f:\n",
    "            magma_odinw_results.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09093a16-88cf-406e-9ff2-c5029faa1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt5_piqa_emr = extract_key_from_json(gpt5_piqa, key='exact_match_rate')\n",
    "pi0_piqa_emr = extract_key_from_json(pi0_hf_piqa, key='exact_match_rate')\n",
    "magma_piqa_emr = extract_key_from_json(magma_piqa, key='exact_match_rate')\n",
    "print(\"pi0 piqa emr:\", pi0_piqa_emr, \"gpt5 piqa emr:\", gpt5_piqa_emr, \"magma piqa emr:\", magma_piqa_emr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e239f3e-d34e-4872-ad8f-f9715752ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt5_bfcl_emr = [28.5]\n",
    "pi0_bfcl_emr = extract_key_from_json(pi0_hf_bfcl_inference, key='exact_match_accuracy')\n",
    "# magma_bfcl_emr = extract_key_from_json(magma_bfcl_inference, key='exact_match_accuracy')\n",
    "print(\"pi0 bfcl emr:\", pi0_bfcl_emr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b7b62-7c27-4732-ae72-6d6c53c97451",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt5_sqa3d_emr = extract_key_from_json(gpt5_sqa3d, key='exact_match_rate')\n",
    "pi0_sqa3d_emr = extract_key_from_json(pi0_hf_sqa3d, key='exact_match_rate')\n",
    "magma_sqa3d_emr = extract_key_from_json(magma_sqa3d, key='exact_match_rate_with_invalids')\n",
    "print(\"pi0 sqa3d emr:\", pi0_sqa3d_emr, \"gpt5 sqa3d emr:\", gpt5_sqa3d_emr, \"magma sqa3d emr:\", magma_sqa3d_emr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e07d0b-a745-4140-af32-e5e69b74648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt5_robovqa_emr = extract_key_from_json(gpt5_robovqa, key='exact_match_rate')\n",
    "pi0_robovqa_emr = extract_key_from_json(pi0_hf_robovqa, key='exact_match_accuracy')\n",
    "magma_robovqa_emr = extract_key_from_json(magma_robovqa, key='exact_match_rate_with_invalids')\n",
    "print(\"pi0 robovqa emr:\", pi0_robovqa_emr, \"gpt5 robovqa emr:\", gpt5_robovqa_emr, \"magma robovqa emr:\", magma_robovqa_emr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e993e84-51f3-441d-a37a-0c7f82cc264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt5_overcooked_emr = extract_key_from_json(gpt5_overcooked, key='exact_match')[0]\n",
    "pi0_overcooked_emr = extract_key_from_json(pi0_base_overcooked, key='exact_match_rate')\n",
    "# magma_overcooked_emr = extract_key_from_json(magma_overcooked, key='exact_match_rate')\n",
    "print(\"pi0 overcooked emr:\", pi0_overcooked_emr, \"gpt5 overcooked emr:\", gpt5_overcooked_emr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7782aad3-3f85-43ae-8cbc-41ced8c960e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all the odinw results and extract the exact match rate\n",
    "gpt5_odinw_emrs = []\n",
    "for result in gpt5_odinw:\n",
    "    gpt5_odinw_emrs.extend(extract_key_from_json(result, key='exact_match_rate'))\n",
    "# iterate through all the pi0 odinw results and extract the exact match rate\n",
    "pi0_odinw_emrs = []\n",
    "for result in pi0_odinw_results:\n",
    "    pi0_odinw_emrs.extend(extract_key_from_json(result, key='exact_match_rate'))\n",
    "\n",
    "magma_odinw_emrs = []\n",
    "for result in magma_odinw_results:\n",
    "    magma_odinw_emrs.extend(extract_key_from_json(result, key='exact_match_rate_with_invalids'))\n",
    "    \n",
    "print(\"pi0 odinw emrs:\", pi0_odinw_emrs, \"gpt5 odinw emrs:\", gpt5_odinw_emrs, \"magma odinw emrs:\", magma_odinw_emrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b0243-048e-4db5-ad14-97ed25f317c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Task': ['PIQA', 'BFCL', 'SQA3D', 'RoboVQA', 'ODINW', 'Overcooked'],\n",
    "    'GPT-5': [np.mean(gpt5_piqa_emr), \n",
    "                              None, \n",
    "                              np.mean(gpt5_sqa3d_emr), \n",
    "                              np.mean(gpt5_robovqa_emr), \n",
    "                              np.mean(gpt5_odinw_emrs), \n",
    "                              np.mean(gpt5_overcooked_emr)],\n",
    "    'Pi-0': [np.mean(pi0_piqa_emr), \n",
    "                             np.mean(pi0_bfcl_emr), \n",
    "                             np.mean(pi0_sqa3d_emr), \n",
    "                             np.mean(pi0_robovqa_emr), \n",
    "                             np.mean(pi0_odinw_emrs), \n",
    "                             np.mean(pi0_overcooked_emr)],\n",
    "    \"Magma\":[np.mean(magma_piqa_emr), \n",
    "                            None, #  np.mean(magma__bfcl_emr),\n",
    "                             np.mean(magma_sqa3d_emr), \n",
    "                             np.mean(magma_robovqa_emr), \n",
    "                             np.mean(magma_odinw_emrs), \n",
    "                            None#  np.mean(magma_overcooked_emr)\n",
    "                            ],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423120e4-851e-49d2-91d4-cebfe0f72085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a data is 0, add a tiny value so it can be visualized on a barplot\n",
    "df = df.replace(0, 0.01)\n",
    "# reshape the dataframe to have a column for model and a column for emr\n",
    "df_melted = df.melt(id_vars=['Task'], value_vars=['GPT-5', 'Pi-0', 'Magma'], var_name='Model', value_name='Exact Match Rate')\n",
    "barplot(df_melted, title='Exact Match Rate Comparison between GPT-5 and Pi-0', ylabel='Exact Match Rate', xlabel='Task', save_path='./emr_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b5c43c-b617-4424-b0e5-897758f34c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt5_openx_namse = {}\n",
    "for result in gpt5_openx:\n",
    "    gpt5_openx_namse.update(extract_per_subtask_metric(result, metric_key='normalized_amse'))\n",
    "pi0_openx_namse = extract_per_subtask_metric(pi0_base_openx, metric_key='normalized_amse')\n",
    "magma_openx_namse = extract_per_subtask_metric(magma_openx, metric_key='normalized_amse')\n",
    "# map the keys in pi0_openx_namse using the openx_subtasks_mapping\n",
    "pi0_openx_namse_mapped = {openx_subtasks_mapping.get(k, k): v for k, v in pi0_openx_namse.items()}\n",
    "# map the keys in magma_openx_namse using the openx_subtasks_mapping\n",
    "magma_openx_namse_mapped = {openx_subtasks_mapping.get(k, k): v for k, v in magma_openx_namse.items()}\n",
    "# map the keys in gpt5_openx_namse using the openx_subtasks_mapping\n",
    "gpt5_openx_namse_mapped = {openx_subtasks_mapping.get(k, k): v for k, v in gpt5_openx_namse.items()}\n",
    "# turn the two dicts into a dataframe\n",
    "# task names are the values in the openx_subtasks_mapping\n",
    "task_names = list(set(openx_subtasks_mapping.values()))\n",
    "# \n",
    "openx_data = {'Task': task_names,\n",
    "              'GPT-5': [gpt5_openx_namse_mapped.get(task, 0) for task in task_names],\n",
    "              'Pi-0': [pi0_openx_namse_mapped.get(task, 0) for task in task_names],\n",
    "              'Magma': [magma_openx_namse_mapped.get(task, 0) for task in task_names]}\n",
    "openx_df = pd.DataFrame(openx_data)\n",
    "openx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bedb332-165d-464a-8845-e638fa905970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 0 with a tiny value so it can be visualized on a barplot\n",
    "openx_df = openx_df.replace(0, 0.01)\n",
    "# make it a melted dataframe\n",
    "openx_df_melted = openx_df.melt(id_vars=['Task'], value_vars=['GPT-5', 'Pi-0','Magma'], var_name='Model', value_name='Normalized AMSE')\n",
    "barplot(openx_df_melted, title='Normalized AMSE Comparison between GPT-5 and Pi-0 on OpenX', ylabel='Normalized AMSE', xlabel='Task', y='Normalized AMSE', save_path='./openx_namse_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multinet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
