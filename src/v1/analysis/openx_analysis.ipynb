{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c699a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys, os, json\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "cur_dir = Path(os.path.abspath(\"\")).parent\n",
    "project_root = cur_dir.parent.parent\n",
    "sys.path.append(str(project_root))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0651b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = [\"#ea5545\",\n",
    "          \"#ede15b\",\n",
    "          \"#87bc45\",\n",
    "          \"#27aeef\",\n",
    "          \"#b33dc6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3b9a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cross_model_brier_mae(results, metric_type='brier_mae'):\n",
    "    \"\"\"Create a plot comparing different MAE metrics across models\n",
    "    Split into 4 vertically stacked subplots with 4 datasets each.\n",
    "    \n",
    "    Args:\n",
    "        results_dir (str): Directory containing results\n",
    "        metric_type (str): Type of metric to plot. One of:\n",
    "            - 'brier_mae'\n",
    "            - 'quantile_filtered_normalized_brier_mae'\n",
    "            - 'normalized_brier_mae'\n",
    "            - 'max_relative_mae'\n",
    "    \"\"\"\n",
    "    # Load results for all models and ensure consistent order with COLORS\n",
    "    models = ['gpt5', 'pi0']\n",
    "    model_colors = {\n",
    "        'gpt5': COLORS[0],     # Red\n",
    "        'pi0': COLORS[4],    # Purple\n",
    "    }\n",
    "    # Get list of all subdatasets -- common ones\n",
    "    subdatasets = sorted(list(results[models[0]].keys()))\n",
    "    \n",
    "    # Set width of bars and positions\n",
    "    width = 0.2  # Slightly wider bars since we have 4 models\n",
    "    \n",
    "    # Dictionary to map models to their metric keys\n",
    "    titles = {\n",
    "        'brier_mae': 'Average MAE',\n",
    "        'quantile_filtered_normalized_brier_mae': 'Quantile Filtered Normalized MAE',\n",
    "        'normalized_brier_mae': 'Normalized Average MAE',\n",
    "        'max_relative_mae': 'Max Relative MAE'\n",
    "    }\n",
    "    metric_keys = {\n",
    "        'brier_mae': {\n",
    "            'gpt5': 'avg_dataset_amae',\n",
    "            'pi0': 'avg_dataset_amae'\n",
    "        },\n",
    "        'quantile_filtered_normalized_brier_mae': {\n",
    "            'gpt5': 'normalized_quantile_filtered_amae',\n",
    "            'pi0': 'normalized_quantile_filtered_amae'\n",
    "        },\n",
    "        'normalized_brier_mae': {\n",
    "            'gpt5': 'normalized_amae',\n",
    "            'pi0': 'normalized_amae'\n",
    "        },\n",
    "        'max_relative_mae': {\n",
    "            'gpt5': 'max_relative_mae',\n",
    "            'pi0': 'max_relative_mae'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Get the appropriate keys for the selected metric\n",
    "    current_metric_keys = metric_keys[metric_type]\n",
    "\n",
    "    # Split datasets into groups of 5\n",
    "    datasets_per_subplot = 5\n",
    "    num_subplots = (len(subdatasets) + datasets_per_subplot - 1) // datasets_per_subplot\n",
    "\n",
    "    # Create figure with subplots and adjust spacing\n",
    "    fig = plt.figure(figsize=(15, 6*num_subplots))\n",
    "    # Add space at the top for the title and legend\n",
    "    gs = plt.GridSpec(num_subplots + 1, 1, height_ratios=[0.3] + [1]*num_subplots, hspace=0.2)\n",
    "    \n",
    "    # Create a special axes for the title and legend\n",
    "    title_ax = fig.add_subplot(gs[0])\n",
    "    title_ax.axis('off')  # Hide the axes\n",
    "    \n",
    "    # Create subplot axes\n",
    "    axs = [fig.add_subplot(gs[i+1]) for i in range(num_subplots)]\n",
    "    \n",
    "    # Plot for each subplot (group of datasets)\n",
    "    for subplot_idx in range(num_subplots):\n",
    "        ax = axs[subplot_idx]\n",
    "        \n",
    "        # Get the datasets for this subplot\n",
    "        start_idx = subplot_idx * datasets_per_subplot\n",
    "        end_idx = min(start_idx + datasets_per_subplot, len(subdatasets))\n",
    "        current_datasets = subdatasets[start_idx:end_idx]\n",
    "        \n",
    "        # Calculate x positions\n",
    "        x = np.arange(len(current_datasets))\n",
    "        \n",
    "        # Plot bars for each model and track min/max values\n",
    "        all_scores = []\n",
    "        for i, model in enumerate(models):\n",
    "            model_scores = []\n",
    "            \n",
    "            for dataset in current_datasets:\n",
    "                score = results[model][dataset][current_metric_keys[model]]\n",
    "                model_scores.append(score)\n",
    "                all_scores.append(score)\n",
    "            # Plot bars with error bars using consistent colors\n",
    "            bars = ax.bar(x + i*width, model_scores, width, \n",
    "                         label=model, color=model_colors[model], alpha=0.8)\n",
    "            \n",
    "            # # Add value labels on top of bars\n",
    "            # for idx, value in enumerate(model_scores):\n",
    "            #     if value > 0:  # Only show non-zero values\n",
    "            #         ax.text(x[idx] + i*width, value, f'{value:.2f}',\n",
    "            #                ha='center', va='bottom', rotation=45,\n",
    "            #                fontsize=20)\n",
    "        \n",
    "        # Calculate y-axis limits for this subplot\n",
    "        non_zero_scores = [s for s in all_scores if s > 0]\n",
    "        if non_zero_scores:\n",
    "            min_val = min(non_zero_scores)\n",
    "            max_val = max(non_zero_scores)\n",
    "            # Start y-axis from 20% below the minimum non-zero value\n",
    "            y_min = max(0, min_val - (max_val - min_val) * 0.2)\n",
    "            # Add 30% padding above maximum value\n",
    "            y_max = max_val + (max_val - min_val) * 0.3\n",
    "            \n",
    "            # Set y-axis limits\n",
    "            ax.set_ylim(y_min, y_max)\n",
    "            \n",
    "            # Add broken axis indicator if not starting from 0\n",
    "            if y_min > 0:\n",
    "                d = .015  # Size of diagonal lines\n",
    "                kwargs = dict(transform=ax.transAxes, color='k', clip_on=False)\n",
    "                ax.plot((-d, +d), (-d, +d), **kwargs)\n",
    "                ax.plot((1 - d, 1 + d), (-d, +d), **kwargs)\n",
    "        \n",
    "        # Customize subplot\n",
    "        metric_label = titles[metric_type]\n",
    "        ax.set_ylabel(metric_label, fontsize=20)\n",
    "        ax.set_xticks(x + width * (len(models)-1)/2)\n",
    "        \n",
    "        current_datasets = [ds.replace('openx_', '') for ds in current_datasets]\n",
    "        current_datasets = [ds[:15]+'...' if len(ds) > 15 else ds for ds in current_datasets]\n",
    "        ax.set_xticklabels(current_datasets, ha='right', fontsize=20)\n",
    "        \n",
    "        #set rotation of xticklabels\n",
    "        ax.tick_params(axis='x', rotation=30)\n",
    "        \n",
    "        ax.grid(True, axis='y', alpha=0.3)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        \n",
    "        # # Add light vertical lines to separate datasets\n",
    "        # for i in x:\n",
    "        #     ax.axvline(i - width/2, color='gray', linestyle='-', alpha=0.1)\n",
    "    \n",
    "    # Add overall title\n",
    "    title_ax.text(0.5, 0.7, f'{metric_label} Comparison Across Subdatasets for OpenX',\n",
    "                 fontsize=24, ha='center', va='bottom')\n",
    "\n",
    "    # Create a single legend for all subplots\n",
    "    handles, labels = axs[0].get_legend_handles_labels()\n",
    "    title_ax.legend(handles, labels, \n",
    "                   loc='center',\n",
    "                   bbox_to_anchor=(0.5, 0.2),\n",
    "                   ncol=len(models),\n",
    "                   fontsize=20)\n",
    "    \n",
    "    # Save the plot\n",
    "    filename = f'model_comparison_{metric_type}_openx.png'\n",
    "    output_path = os.path.abspath(os.path.join(\"plots\", filename))\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3497dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['gpt5', 'pi0']\n",
    "all_results = {'gpt5': {}, 'pi0': {}}\n",
    "\n",
    "with open(Path(f\"{project_root}/src/v1/results/pi0/pi0_base_openx_results.json\"), 'r') as f:\n",
    "    all_results['pi0'] = json.load(f)\n",
    "\n",
    "all_results['gpt5'] = {}\n",
    "for dataset in all_results['pi0'].keys():\n",
    "    gpt5_results_dir = f\"{project_root}/src/v1/results/genesis/gpt_5/low_reasoning/openx/\"\n",
    "    results_file = f\"{dataset}.json\"\n",
    "    with open(Path(gpt5_results_dir) / results_file, 'r') as f:\n",
    "        res = json.load(f)\n",
    "    all_results['gpt5'][dataset] = next(iter(res.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4aec2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cross_model_brier_mae(all_results, metric_type='brier_mae')\n",
    "plot_cross_model_brier_mae(all_results, metric_type='quantile_filtered_normalized_brier_mae')\n",
    "plot_cross_model_brier_mae(all_results, metric_type='normalized_brier_mae')\n",
    "plot_cross_model_brier_mae(all_results, metric_type='max_relative_mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c145a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multinet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
